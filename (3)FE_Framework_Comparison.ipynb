{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44a366-1558-4aec-a0ab-9ad565f5f329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123f2ac-ce4e-4ba5-929b-3da23c2a5bf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final Changes to Data and Size Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8f57b-bd1b-4326-bea8-b52c195a49aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "uni_pure = pd.read_csv('EM_universe.csv', index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48063d05-1329-43c6-9be4-e60e169e41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of uni_pure to use\n",
    "uni = uni_pure.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a82493-50cc-4b23-b1f5-be7dcc40ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to datetiem and sort \n",
    "uni.index = pd.to_datetime(uni.index)\n",
    "uni = uni.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9791dbf-6856-4e85-b436-1401fac23b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns for this analysis\n",
    "uni = uni[['Name', 'ID', 'Price', 'Total Assets', 'Accounts Payable', \n",
    "           'Total Liabilities', 'Net Income', 'EBIT', 'Depreciation', 'Gross Profit', \n",
    "           'Inventories', 'Receivables', 'Sales/Turnover', 'Stockholders Equity', \n",
    "           'Interest Expense', 'EBITDA', 'Free Cash Flow', 'Financing Cash Flow', \n",
    "           'Investing Cash Flow', 'Operating Cash Flow', 'Current Liabilities', \n",
    "           'Current Assets', 'Cost of Goods Sold', 'ROA', 'ROE', 'ROI', 'Gross Profit Margin', \n",
    "           'Operating Profit Margin', 'Net Profit Margin', 'Current Ratio', 'Quick Ratio', \n",
    "           'D/E Ratio', 'Interest Coverage Ratio', 'Asset Turnover Ratio', \n",
    "           'Inventory Turnover Ratio', 'Operational Gearing', 'Revenue Growth', \n",
    "           'Earnings Growth', 'Asset Growth', 'Equity Growth', 'Accruals Ratio', \n",
    "           'Cashflow to Net Income Ratio', 'High Price', 'Low Price', 'Volume', \n",
    "           'Shares', 'Equity', 'Market Cap', 'Alpha', 'Mean_Return', 'Volatility', 'Excess_Return_adjusted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5c740-1dcd-45b4-8710-465e03ccd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "uni.rename(columns={'Excess_Return_adjusted': 'Return'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8c8ea-b98b-48e6-bdd4-341fe3576e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = uni.drop(columns=['Name', 'ID','Return'])\n",
    "y = uni['Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d39f5-3835-4d8e-bb01-b3aa2d6ed3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features to reduce dataset size\n",
    "correlation_matrix = X.corr().abs()\n",
    "\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "highly_correlated = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "\n",
    "reduced_uni = uni.drop(columns=highly_correlated)\n",
    "\n",
    "# Output the reduced DataFrame\n",
    "print(\"Original number of features:\", uni.shape[1])\n",
    "print(\"Reduced number of features:\", reduced_uni.shape[1])\n",
    "print(\"Dropped features:\", highly_correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab1c5d-6950-4a3b-9bde-9832d63e522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reduced_uni.drop(columns=['Name', 'ID','Return'])\n",
    "y = reduced_uni['Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a082db9-794e-427b-b572-58ee7fa7eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 30 most relevant features\n",
    "best_features = SelectKBest(score_func=mutual_info_regression, k=30).fit(X, y)\n",
    "selected_features = best_features.get_support(indices=True)\n",
    "X_filtered = X.iloc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae86a2-6767-4c7e-a416-cc7a89a66bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine metadata and target columns\n",
    "date_index = X_filtered.index\n",
    "\n",
    "metadata = reduced_uni[['Name', 'ID']].reset_index(drop=True)\n",
    "target = reduced_uni[['Return']].reset_index(drop=True)\n",
    "X_filtered = X_filtered.reset_index(drop=True)\n",
    "\n",
    "# Recombine the dataframes\n",
    "df_filtered = pd.concat([metadata, X_filtered, target], axis=1)\n",
    "df_filtered.index = date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48837fe3-b18a-4591-b9b4-afe52fd7af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out companies with insufficient data\n",
    "min_periods = 20\n",
    "company_counts = df_filtered['ID'].value_counts()\n",
    "companies_to_keep = company_counts[company_counts >= min_periods].index\n",
    "filtered_uni = df_filtered[df_filtered['ID'].isin(companies_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e71e6-0963-4ee1-888f-42326ef2281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = filtered_uni.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9c313-24e9-4748-9570-9ded273df9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni.to_csv('Final_FE_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39820dba-5ff5-4c4a-af7f-9e9b8e339739",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions to Track Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a83e62-efbe-454f-8d19-95d8f8a67bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "import psutil\n",
    "import threading\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cc6ef-c0de-4c50-bf07-5a4e0d2a009d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to track CPU usage\n",
    "def get_cpu_usage():\n",
    "    return psutil.cpu_percent(interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f56803-b7d7-4d04-a18d-c5365653c780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to track CPU usage, time and memory\n",
    "def track_resources(function, *args):\n",
    "    start_time = time.time()\n",
    "    start_mem = memory_usage()[0]\n",
    "    process = psutil.Process()\n",
    "    start_cpu_times = process.cpu_times()\n",
    "\n",
    "    result = function(*args)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_mem = memory_usage()[0]\n",
    "    end_cpu_times = process.cpu_times()\n",
    "\n",
    "    user_time = end_cpu_times.user - start_cpu_times.user\n",
    "    system_time = end_cpu_times.system - start_cpu_times.system\n",
    "    total_cpu_time = user_time + system_time\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    avg_cpu_usage = (total_cpu_time / elapsed_time) * 100\n",
    "    \n",
    "    print(f\"Initial memory usage: {start_mem} MB\")\n",
    "    print(f\"Final memory usage: {end_mem} MB\")\n",
    "    print(f\"Average CPU usage during execution: {avg_cpu_usage:.2f}%\")\n",
    "    \n",
    "    time_taken = elapsed_time\n",
    "    memory_used = end_mem - start_mem\n",
    "    cpu_used = avg_cpu_usage\n",
    "    \n",
    "    return (*result, time_taken, memory_used, cpu_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7142f8-bd2c-41e9-801e-78fe31620125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save outputs\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56034d87-af6a-4764-9887-31e7e44dc774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unpickle to csv\n",
    "def pickle_to_csv(pickle_file_path, csv_file_path):\n",
    "\n",
    "    with open(pickle_file_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    df.to_csv(csv_file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64dcce-b52e-4599-af86-d1b08207e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a pickled object\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b12a21-38bb-4eb4-aec3-140e24c1f78d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions to Implement Each Framework\n",
    "\n",
    "Each framework needs to be run in a seperate environment (set up in Anaconda cmd prompt) to ensure no clashes between dependancy versions. See documentation/install information for each package for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b542ab-0ab8-4743-91e9-257adf05a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset\n",
    "uni_pure = pd.read_csv('Final_FE_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb54e52-0198-4665-8f11-013c18c944f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = uni_pure.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980fb60-2e8e-4f4f-bdfb-035361fdfe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain raw data without metrics and ratios\n",
    "raw_data_pure = uni[['Date','Name', 'ID', 'Price', 'Total Assets', 'Accounts Payable', \n",
    "            'Net Income', 'Depreciation', 'Receivables',\n",
    "            'Sales/Turnover', 'Free Cash Flow', 'Financing Cash Flow', \n",
    "           'Investing Cash Flow', 'Operating Cash Flow', 'Shares', 'Return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02608a0a-3331-4fc5-a0f5-30e726991957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain metrics dataset\n",
    "metrics_data_pure = uni[['Date','Name', 'ID', 'ROA', 'ROE', 'ROI', \n",
    "            'Net Profit Margin', 'D/E Ratio', 'Interest Coverage Ratio', \n",
    "            'Operational Gearing', 'Revenue Growth', 'Earnings Growth', \n",
    "            'Asset Growth', 'Equity Growth', 'Accruals Ratio', 'Cashflow to Net Income Ratio',\n",
    "            'Volume', 'Market Cap', 'Alpha', 'Mean_Return', 'Volatility', 'Return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2cc5c-8dc4-44d3-abb2-3e4296fa41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we are working with a copy of the DataFrames\n",
    "raw_data = raw_data_pure.copy()\n",
    "metrics_data = metrics_data_pure.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d798f82d-6db6-42c3-8bca-c6e94259e73c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e44cf-65b9-4631-87c3-176b00d496a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import woodwork as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26567775-2a8c-4235-b268-33306b77b459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the date format explicitly\n",
    "date_format = '%Y-%m-%d'\n",
    "raw_data['Date'] = pd.to_datetime(raw_data['Date'], format=date_format)\n",
    "metrics_data['Date'] = pd.to_datetime(metrics_data['Date'], format=date_format)\n",
    "\n",
    "# Create a unique identifier by combining Name and date\n",
    "raw_data['unique_id'] = raw_data['Name'] + '_' + raw_data['Date'].astype(str)\n",
    "metrics_data['unique_id'] = metrics_data['Name'] + '_' + metrics_data['Date'].astype(str)\n",
    "\n",
    "# Add an index column if it doesn't exist\n",
    "raw_data['index'] = raw_data.index\n",
    "\n",
    "# Add an additional index column to metrics_data\n",
    "metrics_data['metrics_index'] = metrics_data.index\n",
    "\n",
    "# Merge to create the reference\n",
    "metrics_data = metrics_data.merge(raw_data[['unique_id']], on='unique_id', how='left')\n",
    "metrics_data.rename(columns={'unique_id': 'raw_unique_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da9802-76eb-4f05-898f-9d7eecc3c696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize woodwork schema\n",
    "raw_data.ww.init(name='raw_data', index='unique_id', time_index='Date')\n",
    "metrics_data.ww.init(name='metrics_data', index='metrics_index', time_index='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc45b46f-e56d-49c1-8a83-e15568e2f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuretools_engineering(raw_data, metrics_data=None):\n",
    "\n",
    "    raw_data_copy = raw_data.copy()\n",
    "    metrics_data_copy = metrics_data.copy() if metrics_data is not None else None\n",
    "    \n",
    "    # Drop the 'Return' column from the copied dataframes\n",
    "    return_column = raw_data_copy['Return']\n",
    "    raw_data_copy = raw_data_copy.drop(columns=['Return'])\n",
    "\n",
    "    if metrics_data_copy is not None:\n",
    "        metrics_data_copy = metrics_data_copy.drop(columns=['Return'])\n",
    "\n",
    "    # Initialize woodwork schemas\n",
    "    raw_data_copy.ww.init(name='raw_data', index='unique_id', time_index='Date')\n",
    "    if metrics_data_copy is not None:\n",
    "        metrics_data_copy.ww.init(name='metrics_data', index='metrics_index', time_index='Date')\n",
    "\n",
    "    # Create the entity set\n",
    "    es = ft.EntitySet(id='company_data')\n",
    "    es = es.add_dataframe(dataframe_name='raw_data', dataframe=raw_data_copy)\n",
    "\n",
    "    if metrics_data_copy is not None:\n",
    "        es = es.add_dataframe(dataframe_name='metrics_data', dataframe=metrics_data_copy)\n",
    "        es = es.add_relationship('raw_data', 'unique_id', 'metrics_data', 'raw_unique_id')\n",
    "    \n",
    "    # Define transformation primitives\n",
    "    trans_primitives = [\n",
    "        ft.primitives.Year, \n",
    "        ft.primitives.Month, \n",
    "        ft.primitives.Weekday, \n",
    "        ft.primitives.CumSum, \n",
    "        ft.primitives.CumMean, \n",
    "        ft.primitives.CumMin, \n",
    "        ft.primitives.CumMax, \n",
    "        ft.primitives.Diff, \n",
    "        ft.primitives.TimeSince, \n",
    "    ]\n",
    "    \n",
    "    # Run deep feature synthesis\n",
    "    feature_matrix, feature_defs = ft.dfs(entityset=es, target_dataframe_name='raw_data', trans_primitives=trans_primitives)\n",
    "    \n",
    "    # Add back the 'Return' column to the feature matrix\n",
    "    feature_matrix['Return'] = return_column\n",
    "    \n",
    "    return feature_matrix, feature_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2e03d-8e09-4cb4-a97f-87fab76e2382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the function with just raw data\n",
    "raw_features_ft, raw_feature_defs_ft, raw_ft_time, raw_ft_mem, raw_ft_cpu = track_resources(featuretools_engineering, raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed78222-a910-48cf-9c8b-d9bdfd913e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the function with both datasets\n",
    "metrics_features_ft, metrics_feature_defs_ft, metrics_ft_time, metrics_ft_mem, metrics_ft_cpu = track_resources(featuretools_engineering, raw_data, metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568f452-9650-4c9b-bf36-ec5e02ca51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the outputs using pickle\n",
    "save_object(raw_features_ft, 'raw_features_ft.pkl')\n",
    "save_object(raw_feature_defs_ft, 'raw_feature_defs_ft.pkl')\n",
    "save_object(metrics_features_ft, 'metrics_features_ft.pkl')\n",
    "save_object(metrics_feature_defs_ft, 'metrics_feature_defs_ft.pkl')\n",
    "    \n",
    "# Save resource usage data\n",
    "resource_usage_data = {\n",
    "    'raw_ft_time': raw_ft_time,\n",
    "    'raw_ft_mem': raw_ft_mem,\n",
    "    'raw_ft_cpu': raw_ft_cpu,\n",
    "    'metrics_ft_time': metrics_ft_time,\n",
    "    'metrics_ft_mem': metrics_ft_mem,\n",
    "    'metrics_ft_cpu': metrics_ft_cpu\n",
    "}\n",
    "save_object(resource_usage_data, 'resource_usage_data_ft.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12b0e7-6a4e-4cb0-888f-6c42f5c16d86",
   "metadata": {
    "tags": []
   },
   "source": [
    " ### TSFresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ac06b-be23-41a1-8920-a0e92e94f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import EfficientFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35617b15-fd86-43b7-bf38-5b288c1c01a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for feature engineering with TSFresh\n",
    "def tsfresh_engineering(data):\n",
    "\n",
    "    data = data.copy()\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    # Define value variables \n",
    "    value_vars = list(data.columns)\n",
    "    value_vars.remove('Date')\n",
    "    value_vars.remove('Name')\n",
    "    value_vars.remove('ID')\n",
    "    value_vars.remove('Return')\n",
    "    \n",
    "    # Reshape the data for tsfresh\n",
    "    ts_data = data.melt(id_vars=['Date', 'Name'], value_vars=value_vars, var_name='variable', value_name='value')\n",
    "    \n",
    "    # Combine 'Name' and 'Date' to create a unique ID for each company at each date\n",
    "    ts_data['id'] = ts_data['Name'] + '_' + ts_data['Date'].astype(str)\n",
    "    \n",
    "    # Extract features using tsfresh\n",
    "    extracted_features = extract_features(\n",
    "        ts_data, \n",
    "        column_id=\"id\", \n",
    "        column_sort=\"Date\", \n",
    "        column_value=\"value\",\n",
    "        default_fc_parameters=EfficientFCParameters(),\n",
    "        n_jobs=8\n",
    "    )\n",
    "    \n",
    "    # Impute missing values in the extracted features\n",
    "    impute(extracted_features)\n",
    "    \n",
    "    # Split the 'id' back into 'Name' and 'Date' columns\n",
    "    extracted_features['Name'] = extracted_features.index.str.split('_').str[0]\n",
    "    extracted_features['Date'] = pd.to_datetime(extracted_features.index.str.split('_').str[1])\n",
    "    \n",
    "    # Merge the extracted features back with the original data\n",
    "    final_data = pd.merge(data, extracted_features, on=['Name', 'Date'], how='left')\n",
    "    \n",
    "    # Align the target column with the final dataset\n",
    "    target = final_data['Return']\n",
    "    \n",
    "    return final_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0a8f4-676a-4586-b73f-f7cc5df91aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the function for the raw dataset\n",
    "raw_features_tf, raw_feature_target_tf, raw_tf_time, raw_tf_mem, raw_tf_cpu = track_resources(tsfresh_engineering, raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337f6fc-664e-4e2f-ac9d-91287bbe5dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the function for the extended dataset\n",
    "metrics_features_tf, metrics_feature_target_tf, metrics_tf_time, metrics_tf_mem, metrics_tf_cpu = track_resources(tsfresh_engineering, uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d4365e-24b2-4e23-9c47-a74369cff46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the outputs using pickle\n",
    "save_object(raw_features_tf, 'raw_features_tf.pkl')\n",
    "save_object(raw_feature_target_tf, 'raw_feature_defs_tf.pkl')\n",
    "save_object(metrics_features_tf, 'metrics_features_tf.pkl')\n",
    "save_object(metrics_feature_target_tf, 'metrics_feature_defs_tf.pkl')\n",
    "    \n",
    "# Save resource usage data\n",
    "resource_usage_data = {\n",
    "    'raw_tf_time': raw_tf_time,\n",
    "    'raw_tf_mem': raw_tf_mem,\n",
    "    'raw_tf_cpu': raw_tf_cpu,\n",
    "    'metrics_tf_time': metrics_tf_time,\n",
    "    'metrics_tf_mem': metrics_tf_mem,\n",
    "    'metrics_tf_cpu': metrics_tf_cpu\n",
    "}\n",
    "save_object(resource_usage_data, 'resource_usage_data_tf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0968229-1c8e-4274-869f-5dd2f65b02ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Featurewiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f10855-a14e-4a8e-b58b-3ffaeb0c1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import FeatureWiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160c6f5-1591-4cd8-8cd9-30d035cdfa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurewiz_engineering(data):\n",
    "    \n",
    "    # Ensure date is in datetime format\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    # Preserve Date and Name columns\n",
    "    preserved_columns = data[['Date', 'Name', 'ID','Return']]\n",
    "\n",
    "    # Sort data by Company ID and Date to respect the time series order\n",
    "    data = data.sort_values(by=['Name', 'Date'])\n",
    "\n",
    "    # Convert all numeric columns to appropriate types and drop non-numeric features\n",
    "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    X = data[numeric_columns].drop(columns=['Return'])\n",
    "    y = data['Return']\n",
    "\n",
    "    # Use FeatureWiz \n",
    "    fwiz = FeatureWiz(\n",
    "        feature_engg=['interactions', 'groupby', 'target'],  \n",
    "        corr_limit=0.90, \n",
    "        verbose=2, \n",
    "        group_by_columns=['Name'], \n",
    "        date_columns=['Date'],  \n",
    "        scalers='std'\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data using FeatureWiz\n",
    "    X_selected, y_transformed = fwiz.fit_transform(X, y)\n",
    "    \n",
    "    # Re-attach the Date and Name columns\n",
    "    X_selected = pd.concat([preserved_columns.reset_index(drop=True), X_selected.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return X_selected, fwiz.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e0726-610d-41ba-b8d4-aac88439e1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run function for raw dataset\n",
    "raw_features_fw, raw_feature_names_fw, raw_fw_time, raw_fw_mem, raw_fw_cpu = track_resources(featurewiz_engineering, raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf3b2e-b5b9-4265-8e84-52c5eec7c0bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run function for extended dataset\n",
    "metrics_features_fw, metrics_feature_names_fw, metrics_fw_time, metrics_fw_mem, metrics_fw_cpu = track_resources(featurewiz_engineering, uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dcb31b-3c0f-4e4b-9528-80218ef8c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the outputs using pickle\n",
    "save_object(raw_features_fw, 'raw_features_fw.pkl')\n",
    "save_object(raw_feature_names_fw, 'raw_feature_names_fw.pkl')\n",
    "save_object(metrics_features_fw, 'metrics_features_fw.pkl')\n",
    "save_object(metrics_feature_names_fw, 'metrics_feature_names_fw.pkl')\n",
    "    \n",
    "# Save resource usage data\n",
    "resource_usage_data = {\n",
    "    'raw_fw_time': raw_fw_time,\n",
    "    'raw_fw_mem': raw_fw_mem,\n",
    "    'raw_fw_cpu': raw_fw_cpu,\n",
    "    'metrics_fw_time': metrics_fw_time,\n",
    "    'metrics_fw_mem': metrics_fw_mem,\n",
    "    'metrics_fw_cpu': metrics_fw_cpu\n",
    "}\n",
    "save_object(resource_usage_data, 'resource_usage_data_fw.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1242b-038a-4236-a2d6-19867f7ae134",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821cad6-d4c6-49ca-bb6b-fdb75aba6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import setup, compare_models, pull, get_config\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507ec56-f86c-4457-9002-d14c72a376b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove spaces from column names and convert to camelCase\n",
    "def clean_column_names(data):\n",
    "    data.columns = [col.replace(' ', '') for col in data.columns]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80b039-52c3-463b-9ea0-fad317f859e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "raw_data_clean = clean_column_names(raw_data)\n",
    "uni_clean =  clean_column_names(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9a5e-8c94-46be-94cf-59f21c39e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering with PyCaret ensuring consistent feature naming\n",
    "def pycaret_engineering(data):\n",
    "# Ensure date is in datetime format\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    # Sort data by Date to maintain the time series order\n",
    "    data = data.sort_values(by='Date')\n",
    "\n",
    "    # Ignore columns\n",
    "    ignored_columns = data[['Date', 'Name', 'ID', 'Return']].reset_index(drop=True)\n",
    "    numeric_data = data.drop(columns=['Date', 'Name', 'ID', 'Return'])\n",
    "\n",
    "    # Generate polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "    poly_features = poly.fit_transform(numeric_data)\n",
    "\n",
    "    # Get feature names for the polynomial features\n",
    "    poly_feature_names = poly.get_feature_names_out(numeric_data.columns)\n",
    "    \n",
    "    # Convert to DataFrame \n",
    "    poly_features_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "    \n",
    "    # Replace any spaces with underscores in feature names after transformation\n",
    "    poly_features_df.columns = poly_features_df.columns.str.replace(' ', '_')\n",
    "\n",
    "    # Concatenate polynomial features with the ignored columns\n",
    "    processed_data = pd.concat([ignored_columns, poly_features_df], axis=1)\n",
    "\n",
    "    # Set up PyCaret for regression with the new data\n",
    "    reg = setup(\n",
    "        data=processed_data,\n",
    "        target='Return',\n",
    "        ignore_features=['Date', 'Name', 'ID'],  \n",
    "        session_id=123,\n",
    "        feature_selection=True,\n",
    "        remove_multicollinearity=True,\n",
    "        group_features={'company_id': 'ID'},\n",
    "        n_jobs=10,\n",
    "        train_size=0.99,  \n",
    "        verbose = 2,\n",
    "        polynomial_features=False\n",
    "    )\n",
    "\n",
    "    # Get the transformed training and testing data\n",
    "    X_train = get_config('X_train')\n",
    "    X_test = get_config('X_test')\n",
    "    \n",
    "    # Concatenate the training and testing data to get the full dataset\n",
    "    processed_features = pd.concat([X_train, X_test], axis=0).sort_index()\n",
    "\n",
    "    # Reattach the ignored columns \n",
    "    final_dataset = pd.concat([ignored_columns, processed_features.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return final_dataset,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677f58d-0000-49ae-9a61-7d477a1976c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function on raw dataset\n",
    "raw_features_pc,_, raw_pc_time, raw_pc_mem, raw_pc_cpu = track_resources(pycaret_engineering, raw_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b9284-6d38-4c02-90f5-a63d0ce96e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function on extended dataset\n",
    "metrics_features_pc,_, metrics_pc_time, metrics_pc_mem, metrics_pc_cpu = track_resources(pycaret_engineering, uni_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d7588-772e-4f41-891e-107b45443980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the outputs using pickle\n",
    "save_object(raw_features_pc, 'raw_features_pc.pkl')\n",
    "save_object(metrics_features_pc, 'metrics_features_pc.pkl')\n",
    "    \n",
    "# Save resource usage data\n",
    "resource_usage_data = {\n",
    "    'raw_pc_time': raw_pc_time,\n",
    "    'raw_pc_mem': raw_pc_mem,\n",
    "    'raw_pc_cpu': raw_pc_cpu,\n",
    "    'metrics_pc_time': metrics_pc_time,\n",
    "    'metrics_pc_mem': metrics_pc_mem,\n",
    "    'metrics_pc_cpu': metrics_pc_cpu\n",
    "}\n",
    "save_object(resource_usage_data, 'resource_usage_data_pc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c66a6f-312b-4a5a-a932-bd0975c96d4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d291cd9-1fa7-4939-b857-d01d810d76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the resource usage data from each pickle file\n",
    "resource_usage_ft = load_pickle('resource_usage_data_ft.pkl')\n",
    "resource_usage_tf = load_pickle('resource_usage_data_tf.pkl')\n",
    "resource_usage_fw = load_pickle('resource_usage_data_fw.pkl')\n",
    "resource_usage_pc = load_pickle('resource_usage_data_pc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe41480-7c5a-4ddb-b6bd-2d660dc90497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract performance metrics\n",
    "performance_metrics = {\n",
    "    'Method': [\n",
    "        'Featuretools Raw', 'Featuretools Metrics',\n",
    "        'TSFresh Raw', 'TSFresh Metrics',\n",
    "        'Featurewiz Raw', 'Featurewiz Metrics',\n",
    "        'PyCaret Raw', 'PyCaret Metrics'\n",
    "    ],\n",
    "    'Time (s)': [\n",
    "        resource_usage_ft['raw_ft_time'], resource_usage_ft['metrics_ft_time'],\n",
    "        resource_usage_tf['raw_tf_time'], resource_usage_tf['metrics_tf_time'],\n",
    "        resource_usage_fw['raw_fw_time'], resource_usage_fw['metrics_fw_time'],\n",
    "        resource_usage_pc['raw_pc_time'], resource_usage_pc['metrics_pc_time']\n",
    "    ],\n",
    "    'Memory Usage (MB)': [\n",
    "        resource_usage_ft['raw_ft_mem'], resource_usage_ft['metrics_ft_mem'],\n",
    "        resource_usage_tf['raw_tf_mem'], resource_usage_tf['metrics_tf_mem'],\n",
    "        resource_usage_fw['raw_fw_mem'], resource_usage_fw['metrics_fw_mem'],\n",
    "        resource_usage_pc['raw_pc_mem'], resource_usage_pc['metrics_pc_mem']\n",
    "    ],\n",
    "    'Average CPU Usage (%)': [\n",
    "        resource_usage_ft['raw_ft_cpu'], resource_usage_ft['metrics_ft_cpu'],\n",
    "        resource_usage_tf['raw_tf_cpu'], resource_usage_tf['metrics_tf_cpu'],\n",
    "        resource_usage_fw['raw_fw_cpu'], resource_usage_fw['metrics_fw_cpu'],\n",
    "        resource_usage_pc['raw_pc_cpu'], resource_usage_pc['metrics_pc_cpu']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "performance_df = pd.DataFrame(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1242c-2303-483c-955d-67074e4ac33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance metrics to CSV\n",
    "performance_df.to_csv('FE_performance_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3956f4d-9a04-498a-a184-8aca4eae0ee7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accuracy and Interpretability Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a4a07-fe7f-4a42-89ea-5c70fe1a6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be452f7b-ad67-4004-8125-d5b4aa580dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train Random Forest and evaluate metrics\n",
    "def train_and_evaluate_rf(X, y, feature_set_name):\n",
    "    # Define the pipeline \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    # Define 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    # Cross-validation predictions\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=kf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Results for {feature_set_name}:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "    # Train the model on the full dataset to get feature importances\n",
    "    pipeline.fit(X, y)\n",
    "    feature_importances = pipeline.named_steps['rf'].feature_importances_\n",
    "\n",
    "    return mae, rmse, r2, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbb2d5-65fe-4c65-b1c3-ab3d2fab9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all feature sets to CSV\n",
    "pickle_files = [\n",
    "    'raw_features_ft.pkl',\n",
    "    'metrics_features_ft.pkl',\n",
    "    'raw_features_tf.pkl',\n",
    "    'metrics_features_tf.pkl',\n",
    "    'raw_features_fw.pkl',\n",
    "    'metrics_features_fw.pkl',\n",
    "    'raw_features_pc.pkl',\n",
    "    'metrics_features_pc.pkl'\n",
    "]\n",
    "\n",
    "csv_files = [file.replace('.pkl', '.csv') for file in pickle_files]\n",
    "\n",
    "for pickle_file, csv_file in zip(pickle_files, csv_files):\n",
    "    pickle_to_csv(pickle_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a02f97-b827-4883-bc16-b02707318d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "datasets = {\n",
    "    'raw': pd.read_csv('raw_data.csv', index_col='Date'),\n",
    "    'extended': pd.read_csv('uni.csv', index_col='Date'),\n",
    "    'featuretools_raw': pd.read_csv('raw_features_ft.csv'),\n",
    "    'featuretools_extended': pd.read_csv('metrics_features_ft.csv'),\n",
    "    'tsfresh_raw': pd.read_csv('raw_features_tf.csv'),\n",
    "    'tsfresh_extended': pd.read_csv('metrics_features_tf.csv'),\n",
    "    'featurewiz_raw': pd.read_csv('raw_features_fw.csv'),\n",
    "    'featurewiz_extended': pd.read_csv('metrics_features_fw.csv'),\n",
    "    'pycaret_raw': pd.read_csv('raw_features_pc.csv'),\n",
    "    'pycaret_extended': pd.read_csv('metrics_features_pc.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d6159-00da-45a6-a417-88b8db528c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean datasets\n",
    "raw = datasets['raw']\n",
    "extended = datasets['extended']\n",
    "\n",
    "raw = raw.drop(columns=['Unnamed: 0'])\n",
    "extended = extended.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "datasets['raw'] = raw\n",
    "datasets['extended'] = extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa348d-0fa8-4d20-8f0d-46c260ca6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Featuretools datasets\n",
    "ft_raw = datasets['featuretools_raw']\n",
    "ft_ext = datasets['featuretools_extended']\n",
    "\n",
    "ft_raw[['Name', 'Date']] = ft_raw['unique_id'].str.split('_', expand=True)\n",
    "ft_raw['Date'] = pd.to_datetime(ft_raw['Date'])\n",
    "\n",
    "ft_ext[['Name', 'Date']] = ft_ext['unique_id'].str.split('_', expand=True)\n",
    "ft_ext['Date'] = pd.to_datetime(ft_ext['Date'])\n",
    "\n",
    "ft_raw = ft_raw.drop(columns=['unique_id'])\n",
    "ft_ext = ft_ext.drop(columns=['unique_id'])\n",
    "\n",
    "ft_raw.set_index(['Date'], inplace = True)\n",
    "ft_ext.set_index(['Date'], inplace = True)\n",
    "\n",
    "datasets['featuretools_raw'] = ft_raw\n",
    "datasets['featuretools_extended'] = ft_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977bb8c5-4b3e-4c07-b0fa-78ff5cab3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean TSFresh datasets\n",
    "tf_raw = datasets['tsfresh_raw']\n",
    "tf_ext = datasets['tsfresh_extended']\n",
    "\n",
    "\n",
    "tf_raw = tf_raw.drop(columns=['Unnamed: 0'])\n",
    "tf_ext = tf_ext.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "tf_raw.set_index(['Date'], inplace = True)\n",
    "tf_ext.set_index(['Date'], inplace = True)\n",
    "\n",
    "datasets['tsfresh_raw'] = tf_raw\n",
    "datasets['tsfresh_extended'] = tf_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4a45f-f4dc-420f-b901-0e144e9b623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Featurewiz datasets\n",
    "fw_raw = datasets['featurewiz_raw']\n",
    "fw_ext = datasets['featurewiz_extended']\n",
    "\n",
    "fw_raw.set_index(['Date'], inplace = True)\n",
    "fw_ext.set_index(['Date'], inplace = True)\n",
    "\n",
    "fw_raw = fw_raw.drop(columns=['Unnamed: 0'])\n",
    "fw_ext = fw_ext.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "datasets['featurewiz_raw'] = fw_raw\n",
    "datasets['featurewiz_extended'] = fw_ext  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dbd402-482b-48da-8b2a-1adf0d4359e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean PyCaret datasets\n",
    "pc_raw = datasets['pycaret_raw']\n",
    "pc_ext = datasets['pycaret_extended']\n",
    "\n",
    "pc_raw.set_index(['Date'], inplace = True)\n",
    "pc_ext.set_index(['Date'], inplace = True)\n",
    "\n",
    "pc_raw = pc_raw.drop(columns=['Unnamed: 0', '1'])\n",
    "pc_ext = pc_ext.drop(columns=['Unnamed: 0', '1'])\n",
    "\n",
    "datasets['pycaret_raw'] = pc_raw\n",
    "datasets['pycaret_extended'] = pc_ext  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9ae04-f27e-4089-a723-ec356815972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop 0 or +-inf in dataset\n",
    "def clean_dataset(df):\n",
    "    # Drop columns where all values are zeros\n",
    "    df_cleaned = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "    # Drop columns with any NaN or inf values in numeric columns\n",
    "    df_cleaned = df_cleaned.dropna(axis=1, how='any')\n",
    "    df_cleaned = df_cleaned.loc[:, ~df_cleaned.isin([np.inf, -np.inf]).any()]\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0c690-8b1a-45cc-b30c-1e04e624a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all datasets\n",
    "cleaned_datasets = {name: clean_dataset(df) for name, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd5593-ba67-4dc9-b7af-3e5fa16e27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to hold results\n",
    "metrics_index = [\n",
    "    'MAE', \n",
    "    'RMSE', \n",
    "    'R2', \n",
    "    'Gini Feature Importances'\n",
    "]\n",
    "results_df = pd.DataFrame(index=metrics_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffdb403-5b18-4cad-b838-b944b8eee153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the datasets and evaluate each one\n",
    "for name, data in cleaned_datasets.items():\n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=['Return'])\n",
    "    \n",
    "    # Drop non-numeric columns from the feature set\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    \n",
    "    y = data['Return']\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    mae, rmse, r2, feature_importances = train_and_evaluate_rf(X, y, name)\n",
    "\n",
    "    # Populate the results DataFrame\n",
    "    results_df[name] = [\n",
    "        mae, \n",
    "        rmse, \n",
    "        r2, \n",
    "        feature_importances\n",
    "    ]\n",
    "\n",
    "    # Print progress for each dataset\n",
    "    print(f\"Completed evaluation for: {name}\")\n",
    "\n",
    "# Save the results DataFrame to a CSV file\n",
    "results_df.to_csv('rf_evaluation_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7502ce-1a03-45f0-8cda-3540619a8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned datasets\n",
    "datasets_to_save = ['raw', 'extended', 'featuretools_raw', 'tsfresh_raw', \n",
    "                    'featurewiz_raw', 'pycaret_raw', 'tsfresh_extended', \n",
    "                    'featuretools_extended', 'featurewiz_extended', 'pycaret_extended']\n",
    "\n",
    "# Save the selected datasets to CSV\n",
    "for name in datasets_to_save:\n",
    "    cleaned_datasets[name].to_csv(f'cleaned_{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f2c31-162e-402b-9bc3-ca2b5a408b54",
   "metadata": {},
   "source": [
    "## Evaluate Importance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941a2a6-b472-4550-80ed-5eef5c2ecfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluation summary file\n",
    "results_df = pd.read_csv('rf_evaluation_summary.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0990b9e-105e-4404-aa75-56b549ae66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store the top 10 features for each dataset\n",
    "top_features_df = pd.DataFrame(columns=['Dataset', 'Feature', 'Gini Importance'])\n",
    "\n",
    "# Loop through the datasets\n",
    "for name in results_df.columns:\n",
    "    # Extract the Gini importances string\n",
    "    gini_importances_str = results_df.loc['Gini Feature Importances', name]\n",
    "    \n",
    "    # Clean up the string and convert it to a list of floats\n",
    "    gini_importances_str = gini_importances_str.replace('[', '').replace(']', '').replace('\\n', ' ')\n",
    "    gini_importances_list = [float(x) for x in gini_importances_str.split()]\n",
    "    \n",
    "    # Get the feature names from the corresponding dataset\n",
    "    feature_names = cleaned_datasets[name].drop(columns=['Return']).select_dtypes(include=[float, int]).columns.tolist()\n",
    "    \n",
    "    # Ensure that the length of Gini importances matches the number of features\n",
    "    if len(gini_importances_list) == len(feature_names):\n",
    "        # Create a DataFrame for the current dataset's features and Gini importances\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Gini Importance': gini_importances_list\n",
    "        })\n",
    "        \n",
    "        # Sort by Gini importance and get the top 10 features\n",
    "        top_10_features = feature_importance_df.nlargest(11, 'Gini Importance')\n",
    "        \n",
    "        # Add a column for the dataset name\n",
    "        top_10_features['Dataset'] = name\n",
    "        \n",
    "        # Append to the main DataFrame\n",
    "        top_features_df = pd.concat([top_features_df, top_10_features], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Length mismatch between Gini importances and features in dataset: {name}\")\n",
    "\n",
    "# Reorder the columns\n",
    "top_features_df = top_features_df[['Dataset', 'Feature', 'Gini Importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd1979-2506-47aa-b0d9-6b87b6a6619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_df.to_csv('feature_importance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tsfresh_env)",
   "language": "python",
   "name": "tsfresh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
